{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ProConnect360** is a web scraping solution designed to gather detailed profiles of professors from universities and professionals from job platforms like Indeed. It provides insights into their roles, expertise, and locations, storing the data in structured formats like CSV and Excel for analysis, fostering professional connections and academic research."
      ],
      "metadata": {
        "id": "YQcHpK-8527z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-3A0_IE1Ch2l",
        "outputId": "6571f283-2646-4d64-96f0-026270a61eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Aamir Shahzada Khan, Contact: 3835, Job-Description: Lecturer, Email: aamir.shahzada@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/636753931581232459123.JPG\n",
            "Name: Aasma Nijabat, Contact: N/A, Job-Description: Lecturer, Email: aasma.nijabat@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638494724332760590276.jpg\n",
            "Name: Abbas Raza, Contact: N/A, Job-Description: Study leave, Lecturer cum Lab Engineer, Email: abbas.raza@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637915951748091997809.jpg\n",
            "Name: Abdul Basit, Contact: N/A, Job-Description: Principal Lecturer, Email: a.basit@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706417063055230305.jpg\n",
            "Name: Abdul Ghafar, Contact: 3346, Job-Description: Lecturer, Email: abdul.ghafar@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638200032907509923750.jpg\n",
            "Name: Abdul Jamil, Contact: N/A, Job-Description: Lecturer, Email: abdul.Jamil@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638182754096493586649.jpg\n",
            "Name: Abdul Rafay, Contact: 3359, Job-Description: Professor, Email: abdul.rafay@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638198449517129175712.jpg\n",
            "Name: Abdul Rehman Ajmal, Contact: N/A, Job-Description: Lecturer, Email: abdulrehman.ajmal@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637805242509411608941.jpg\n",
            "Name: Abdullah Ashfaq, Contact: N/A, Job-Description: Lecturer, Email: abdullah.ashfaq@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638337530128003193800.jpg\n",
            "Name: Abdullah Hasan, Contact: N/A, Job-Description: Lecturer, Email: abdullah.hassan@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706587703361364336.jpg\n",
            "Name: Abdullah Khalid, Contact: 3676, Job-Description: Lecturer, Email: abdullah.khalid@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637286944954370312437.jpg\n",
            "Name: Abdullah Miraj, Contact: N/A, Job-Description: Lecturer, Email: , HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637411331644310790431.jpg\n",
            "Name: Adeel Ashraf, Contact: N/A, Job-Description: Study Leave, Lecturer, Email: adeel.ashraf@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637279018632253548225.png\n",
            "Name: Adeel Ashraf, Contact: N/A, Job-Description: Lecturer, Email: adeel_ashraf@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637279018632253548225.png\n",
            "Name: Adeel Salam Shaikh, Contact: 3371, Job-Description: Assistant Professor, Email: adeel.shaikh@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638198449699639837963.jpg\n",
            "Name: Adil Masood Qazi, Contact: 3861, Job-Description: Assistant Professor, Email: adil.qazi@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638098201052249974224.jpg\n",
            "Name: Adnan Ahmad Naeem, Contact: 3434, Job-Description: Assistant Professor, Email: adnan.naeem@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638568966393028485302.jpg\n",
            "Name: Adnan Amjad, Contact: 3464, Job-Description: Lecturer, Email: adnan.amjad@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638228526831174478117.JPG\n",
            "Name: Adnan Baig, Contact: N/A, Job-Description: Lecturer, Email: adnan.baig@skt.umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Afifa Tanweer, Contact: 7030, Job-Description: Acting Chairperson Department of Nutrition and Dietetics, Assistant Professor, Email: afifa.tanweer@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638515570656539551653.jpg\n",
            "Name: Afnan Iftikhar, Contact: N/A, Job-Description: Lecturer, Email: afnaniftikhar@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706413628798698879.jpg\n",
            "Name: Ahad Hanif, Contact: 3687, Job-Description: Lecturer, Email: ahad.hanif@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/63623289264091693991.png\n",
            "Name: Ahmad Abduhu, Contact: 3873, Job-Description: Lab Engineer, Email: abduhu@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Ahmad Fraz, Contact: 3491, Job-Description: Assistant Professor, Email: ahmad.fraz@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638098200266742078674.jpg\n",
            "Name: Ahmad Hussain, Contact: N/A, Job-Description: Lecturer, Email: ahmad.hussain@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Ahmad Raza, Contact: N/A, Job-Description: Lab Demonstrator, Email: ahmad_raza@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638669320355713991571.jpg\n",
            "Name: Ahmad Shaoor, Contact: N/A, Job-Description: Lab Engineer, Email: ahmad.shaoor@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Ahmad Sohail Aslam, Contact: 3465, Job-Description: Assistant Professor, Email: ahmad.aslam@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706391619781364978.jpg\n",
            "Name: Ahmad Yar, Contact: N/A, Job-Description: Lab Engineer, Email: ahmad.yar@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638586307655681947568.jpg\n",
            "Name: Ahmed Karim Chaudhari, Contact: N/A, Job-Description: Lab Engineer, Email: , HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638446516775892776589.jpg\n",
            "Name: Ahmed Raza, Contact: N/A, Job-Description: Lecturer, Email: ahmedraza@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638711578848040774804.jpg\n",
            "Name: Ahmed Raza, Contact: N/A, Job-Description: Lecturer, Email: ahmed_raza@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638711578848040774804.jpg\n",
            "Name: Ahsan Ali, Contact: N/A, Job-Description: Lecturer, Email: ahsan.ali@skt.umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Ahtsham Ali, Contact: 3849, Job-Description: Assistant Professor, Email: ahtsham.ali@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/747.jpg\n",
            "Name: Aiman Shahzad, Contact: 6294, Job-Description: Lecturer, Email: aiman.shahzad@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637817312055238816523.jpg\n",
            "Name: Aimen Saleem, Contact: N/A, Job-Description: Lecturer, Email: aimen.saleem@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/63809820052050567050.jpg\n",
            "Name: Aleena Sohail, Contact: N/A, Job-Description: Lecturer, Email: aleena.sohail@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638370230307248438724.jpg\n",
            "Name: Ali Ajwad, Contact: 3679, Job-Description: Study leave, Assistant Professor, Email: ali.ajwad@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/636758057664492327449.png\n",
            "Name: Ali Harris, Contact: N/A, Job-Description: Lecturer, Email: ali.harris@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638711574088565519856.jpg\n",
            "Name: Ali Hussnain, Contact: N/A, Job-Description: Lab Engineer, Email: ali.hussnain@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706590425043600504.jpg\n",
            "Name: Allah Ditta, Contact: N/A, Job-Description: Study Leave, Assistant Professor, Email: allah.ditta@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638059416748772079877.jpg\n",
            "Name: Almas Anwar, Contact: 3492, Job-Description: Lecturer, Email: almas.anwar@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Almina Shafiq, Contact: N/A, Job-Description: Assistant Professor, Email: almina.shafiq@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637279148322585974258.jpg\n",
            "Name: Aly Raza Syed, Contact: 3388, Job-Description: Chairperson Department of Management, Assistant Professor, Email: mgt.cod@umt.edu.pk, aly.raza@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638155114429724537972.jpg\n",
            "Name: Amal Akbar, Contact: N/A, Job-Description: Lab Engineer, Email: amal.akbar@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706594927289884728.jpg\n",
            "Name: Amarah Abdullah, Contact: N/A, Job-Description: Lecturer, Email: amarah.abdullah@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638382367165652915565.jpg\n",
            "Name: Amarah Qureshi, Contact: N/A, Job-Description: Lecturer, Email: amarah.qureshi@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Amber Ishaq, Contact: N/A, Job-Description: Lecturer, Email: amber.ishaq@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638098209715859360585.jpg\n",
            "Name: Amber Waqar, Contact: N/A, Job-Description: Lecturer, Email: , HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Amina Abbas, Contact: N/A, Job-Description: Lecturer, Email: , HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Amina Mehmood, Contact: N/A, Job-Description: Study Leave, Lecturer, Email: amina.mehmood@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637759446872301123230.jpg\n",
            "Name: Amina Shah, Contact: N/A, Job-Description: Lecturer, Email: amina.shah@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637127141389508771950.jpg\n",
            "Name: Amiq Inayat, Contact: N/A, Job-Description: Lecturer, Email: amiq.inayat@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638711578705544432554.jpg\n",
            "Name: Amjad Ali, Contact: N/A, Job-Description: Lecturer, Email: amjad-ali@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Amjad Ali, Contact: 3437, Job-Description: Assistant Professor, Email: amjad.ali@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638706406877478219747.jpg\n",
            "Name: Ammar Haider, Contact: N/A, Job-Description: Lecturer, Email: ammar.haider@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638711578298008067800.jpg\n",
            "Error fetching image for #: Invalid URL '#': No scheme supplied. Perhaps you meant https://#?\n",
            "Name: Ammar Yasir Sajjad, Contact: N/A, Job-Description: Lecturer, Email: ammar.yasir@umt.edu.pk, HEC Approved: FALSE, Photo Link: N/A\n",
            "Name: Ammara Arshad, Contact: N/A, Job-Description: Lecturer, Email: ammara.arshad@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638515603745697235569.jpg\n",
            "Name: Amna, Contact: N/A, Job-Description: Lecturer, Email: Ms.amna@skt.umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Amna Ali, Contact: N/A, Job-Description: Lecturer, Email: , HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638370297212960356296.jpg\n",
            "Name: Amna Faisal, Contact: N/A, Job-Description: Lab Engineer, Email: amna.faisal@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638554309455194971519.jpg\n",
            "Name: Amna Farooq, Contact: N/A, Job-Description: Lecturer, Email: amna.farooq@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638024752805584353558.jpg\n",
            "Name: Amna Hafeez, Contact: 0, Job-Description: Program Head â€“ Aviation Management, Lecturer, Email: amnahafeez@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/636457526229848926984.jpg\n",
            "Name: Amna Khalid, Contact: 3869, Job-Description: Acting Chairperson,Department of Visual Communication Design, Assistant Professor, Email: dig.cod@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/638098208915512686551.jpg\n",
            "Name: Amna Malik, Contact: N/A, Job-Description: Lecturer, Email: amna.malik@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637106419383473715347.jpg\n",
            "Name: Amna Manzoor, Contact: 3869, Job-Description: Assistant Professor, Email: amna.manzoor@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/\n",
            "Name: Amna Murad, Contact: 3462, Job-Description: Lecturer, Email: amna.murad@umt.edu.pk, HEC Approved: FALSE, Photo Link: https://admin.umt.edu.pk/Media/UserProfile/637148736476338520633.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4501e4214cdd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Extract image URL from the faculty's individual page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mimage_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_image_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaculty_page_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Print or store the extracted data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4501e4214cdd>\u001b[0m in \u001b[0;36mextract_image_url\u001b[0;34m(faculty_url)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaculty_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Try to find the image using the initial method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mrejections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         for (self.markup, self.original_encoding, self.declared_html_encoding,\n\u001b[0m\u001b[1;32m    329\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m              self.builder.prepare_markup(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[0;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mtry_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muser_specified_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         dammit = UnicodeDammit(\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mknown_definite_encodings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknown_definite_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/dammit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, known_definite_encodings, smart_quotes_to, is_html, exclude_encodings, user_encodings, override_encodings)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mencodings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_usable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mchardet_dammit\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mchardet_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chardet/__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(byte_str, should_rename_legacy)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_rename_legacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshould_rename_legacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chardet/universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMacRomanProber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                     self.result = {\n\u001b[1;32m    276\u001b[0m                         \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chardet/charsetgroupprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chardet/mbcharsetprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcoding_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMachineState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mchar_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoding_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_charlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbyte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chardet/codingstatemachine.py\u001b[0m in \u001b[0;36mget_current_charlen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_current_charlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_char_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Project: ProConnect360 - University Faculty Scraper\n",
        "\n",
        "Description:\n",
        "This script is designed to scrape faculty data from university websites, providing detailed insights\n",
        "into professors' profiles. It gathers information such as names, contact details, job descriptions,\n",
        "emails, and profile images. The data is processed and displayed for further analysis.\n",
        "\n",
        "Features:\n",
        "1. Extracts faculty profile data from the UMT website.\n",
        "2. Scrapes details like Name, Contact, Job Description, Email, and Profile Image.\n",
        "3. Identifies whether the faculty is HEC approved based on the job description.\n",
        "4. Handles dynamic image URL extraction from individual faculty pages.\n",
        "5. Outputs all scraped data in a structured format for easy review.\n",
        "\n",
        "Modules Used:\n",
        "- requests: For sending HTTP requests to fetch web pages.\n",
        "- BeautifulSoup (bs4): For parsing HTML and extracting required information.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_image_url(faculty_url):\n",
        "    \"\"\"Extracts the profile image URL from the faculty's individual page.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(faculty_url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Try to find the image using the initial method\n",
        "        img_tag = soup.find(\"img\", id=\"ctl00_cphContent_imgProfile\")\n",
        "        if img_tag and \"src\" in img_tag.attrs:\n",
        "            return img_tag[\"src\"]\n",
        "\n",
        "        # If not found, try to find it in the alternative div\n",
        "        img_tag_alternate = soup.find(\"div\", class_=\"col-md-3\").find(\"img\") if soup.find(\"div\", class_=\"col-md-3\") else None\n",
        "        if img_tag_alternate and \"src\" in img_tag_alternate.attrs:\n",
        "            return img_tag_alternate[\"src\"]\n",
        "\n",
        "        return \"N/A\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching image for {faculty_url}: {e}\")\n",
        "        return \"N/A\"\n",
        "\n",
        "# URL of the UMT faculty page\n",
        "url = \"https://www.umt.edu.pk/faculty.aspx\"\n",
        "\n",
        "# Headers (to prevent blocking of requests by the server)\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
        "\n",
        "# Fetch the content of the webpage\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find the table rows containing faculty data\n",
        "rows = soup.find_all(\"tr\")\n",
        "\n",
        "# Loop through each row and extract the required data\n",
        "for row in rows:\n",
        "    name_cell = row.find(\"td\", class_=\"person-name\")\n",
        "    contact_cell = row.find(\"td\", class_=\"person-contact\")\n",
        "    job_description_cell = row.find(\"td\", class_=\"job-description\")\n",
        "    email_cell = row.find(\"td\", class_=\"person-email\")\n",
        "\n",
        "    if name_cell and job_description_cell and email_cell:\n",
        "        name = name_cell.get_text(strip=True)\n",
        "        contact = contact_cell.get_text(strip=True) if contact_cell else \"N/A\"\n",
        "        contact = contact if len(contact) > 0 else \"N/A\"\n",
        "        job_description = job_description_cell.get_text(strip=True)\n",
        "\n",
        "        # Extract email from the title attribute of <a> tag\n",
        "        email_tag = email_cell.find(\"a\")\n",
        "        email = email_tag[\"title\"] if email_tag and \"title\" in email_tag.attrs else \"N/A\"\n",
        "\n",
        "        # Check if job description contains \"HEC\" (case-insensitive)\n",
        "        hec_approved = \"TRUE\" if \"hec\" in job_description.lower() else \"FALSE\"\n",
        "\n",
        "        # Extract faculty page link\n",
        "        faculty_link_tag = name_cell.find(\"a\")\n",
        "        faculty_page_url = faculty_link_tag[\"href\"] if faculty_link_tag and \"href\" in faculty_link_tag.attrs else \"N/A\"\n",
        "        # Create full URL if the href is relative\n",
        "        if faculty_page_url.startswith('/'):\n",
        "            faculty_page_url = \"https://www.umt.edu.pk\" + faculty_page_url\n",
        "\n",
        "        # Extract image URL from the faculty's individual page\n",
        "        image_url = extract_image_url(faculty_page_url)\n",
        "\n",
        "        # Print or store the extracted data\n",
        "        print(f\"Name: {name}, Contact: {contact}, Job-Description: {job_description}, Email: {email}, HEC Approved: {hec_approved}, Photo Link: {image_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Project: JobScrape360 - Save Job Listings to CSV and Excel\n",
        "\n",
        "Description:\n",
        "This script automates the process of scraping Python job listings from Indeed Pakistan for Lahore.\n",
        "It extracts details such as job titles, company names, locations, and job descriptions,\n",
        "and saves the data into both a CSV file and an Excel workbook for analysis.\n",
        "\n",
        "Features:\n",
        "1. Automates job search for \"Python Developer\" in Lahore on Indeed.\n",
        "2. Extracts comprehensive details for each job posting.\n",
        "3. Saves the scraped data to a structured CSV file and an Excel workbook.\n",
        "4. Implements pagination to scrape job listings across multiple pages.\n",
        "5. Simulates human-like interaction with random delays to reduce detection.\n",
        "\n",
        "Modules Used:\n",
        "- Selenium: For browser automation and interaction with dynamic elements.\n",
        "- random: To add randomized delays for human-like interactions.\n",
        "- csv: To save scraped data in CSV format.\n",
        "- openpyxl: To save data into an Excel workbook.\n",
        "- time: For managing delays during scraping.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from openpyxl import Workbook\n",
        "\n",
        "# Helper function to simulate human-like random delays\n",
        "def random_sleep(min_time=2, max_time=5):\n",
        "    \"\"\"\n",
        "    Introduces a randomized delay to mimic human interaction.\n",
        "\n",
        "    Args:\n",
        "        min_time (int): Minimum delay in seconds.\n",
        "        max_time (int): Maximum delay in seconds.\n",
        "    \"\"\"\n",
        "    time.sleep(random.uniform(min_time, max_time))\n",
        "\n",
        "# Step 1: Set up the WebDriver (Chrome in this case)\n",
        "# Using ChromeDriverManager to ensure the correct driver version is installed automatically.\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "driver.implicitly_wait(10)  # Set an implicit wait for locating elements\n",
        "\n",
        "# Step 2: Create a CSV file and write the headers\n",
        "csv_file = open('lahore_python_jobs.csv', mode='w', newline='', encoding='utf-8')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['Job Title', 'Company Name', 'Location', 'Job Description'])  # Add column headers\n",
        "\n",
        "# Step 3: Create an Excel workbook and write the headers\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Python Jobs\"\n",
        "ws.append(['Job Title', 'Company Name', 'Location', 'Job Description'])  # Add column headers\n",
        "\n",
        "# Step 4: Navigate to the Indeed Pakistan job search page\n",
        "driver.get(\"https://pk.indeed.com/\")\n",
        "random_sleep(3, 6)\n",
        "\n",
        "# Step 5: Enter the job title in the search box\n",
        "job_search_box = driver.find_element(By.ID, \"text-input-what\")\n",
        "for char in \"Python Developer\":  # Simulate typing character by character\n",
        "    job_search_box.send_keys(char)\n",
        "    random_sleep(0.1, 0.3)\n",
        "\n",
        "# Step 6: Enter the location in the search box\n",
        "location_search_box = driver.find_element(By.ID, \"text-input-where\")\n",
        "location_search_box.clear()  # Clear the default location\n",
        "random_sleep(1, 2)\n",
        "location_search_box.send_keys(\"Lahore\")  # Set the location to Lahore\n",
        "random_sleep(1, 2)\n",
        "\n",
        "# Submit the search by pressing ENTER\n",
        "location_search_box.send_keys(Keys.ENTER)\n",
        "random_sleep(5, 7)\n",
        "\n",
        "# Function to scrape job details from the current page\n",
        "def scrape_jobs_from_page():\n",
        "    \"\"\"\n",
        "    Scrapes job details from the current page and saves them to both CSV and Excel files.\n",
        "    \"\"\"\n",
        "    jobs = driver.find_elements(By.CLASS_NAME, 'job_seen_beacon')  # Locate job postings\n",
        "    for job in jobs:\n",
        "        try:\n",
        "            # Click the job title link to open the job description\n",
        "            job_title_link = job.find_element(By.CSS_SELECTOR, 'a.jcs-JobTitle')\n",
        "            job_title_link.click()\n",
        "            random_sleep(3, 5)\n",
        "\n",
        "            # Extract job details from the job description page\n",
        "            job_title = driver.find_element(By.XPATH, \"//h2[contains(@class,'jobsearch-JobInfoHeader-title')]\").text\n",
        "            company_name = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='inlineHeader-companyName']\").text\n",
        "            job_location = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='inlineHeader-companyLocation']\").text\n",
        "            job_description = driver.find_element(By.ID, \"jobDescriptionText\").text\n",
        "\n",
        "            # Write the extracted details to the CSV file\n",
        "            csv_writer.writerow([job_title, company_name, job_location, job_description])\n",
        "\n",
        "            # Write the extracted details to the Excel sheet\n",
        "            ws.append([job_title, company_name, job_location, job_description])\n",
        "\n",
        "            # Navigate back to the job listings page\n",
        "            driver.back()\n",
        "            random_sleep(5, 7)\n",
        "        except Exception as e:\n",
        "            # Log any errors encountered during scraping\n",
        "            print(f\"Failed to process job due to: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# Function to navigate to the next page of job listings\n",
        "def go_to_next_page():\n",
        "    \"\"\"\n",
        "    Navigates to the next page of job postings if available.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successfully navigated to the next page, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        next_button = driver.find_element(By.CSS_SELECTOR, \"a[data-testid='pagination-page-next']\")\n",
        "        next_button.click()  # Click the \"Next Page\" button\n",
        "        random_sleep(5, 7)\n",
        "        return True\n",
        "    except:\n",
        "        # If the \"Next Page\" button is not found, assume the end of pagination\n",
        "        print(\"No more pages to navigate.\")\n",
        "        return False\n",
        "\n",
        "# Step 7: Loop through all pages and scrape job listings\n",
        "while True:\n",
        "    scrape_jobs_from_page()  # Scrape jobs on the current page\n",
        "    if not go_to_next_page():  # Navigate to the next page, if available\n",
        "        break\n",
        "\n",
        "# Step 8: Clean up and save the data\n",
        "driver.quit()  # Close the browser\n",
        "csv_file.close()  # Close the CSV file\n",
        "wb.save(\"lahore_python_jobs.xlsx\")  # Save the Excel workbook\n",
        "\n",
        "print(\"Job scraping completed. Data saved to 'lahore_python_jobs.csv' and 'lahore_python_jobs.xlsx'.\")\n"
      ],
      "metadata": {
        "id": "sGhBXx5_8oUW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ProConnect360**: This advanced scraping solution efficiently collects and processes faculty profiles from university websites. It scrapes all pages at once, ensuring no profiles are missed due to pagination issues. By gathering all URLs first and leveraging multi-threading, it maximizes resource utilization, reduces reload times, and provides detailed outputs with names, roles, and contacts."
      ],
      "metadata": {
        "id": "b5lQ3Mb56Ukm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Purpose:\n",
        "# This script resolves the issue of Chromium no longer being distributed outside Snap on Ubuntu.\n",
        "# The solution involves adding Debian Buster repositories and configuring package preferences to install Chromium.\n",
        "\n",
        "# Step 1: Add Debian Buster repositories\n",
        "# These repositories provide the necessary packages for Chromium installation.\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Step 2: Add Debian GPG keys\n",
        "# These keys are required to authenticate the Debian repositories and ensure secure package installation.\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "# Convert the keys to the gpg format and save them to the appropriate directory\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Step 3: Set package preferences for Chromium\n",
        "# This ensures that only Chromium-related packages are fetched from the Debian Buster repositories,\n",
        "# while other packages remain sourced from the default Ubuntu repositories.\n",
        "\n",
        "# Note:\n",
        "# The double-blank lines between entries are required for proper configuration.\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "EOF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfPIu64pRDmK",
        "outputId": "0394ef1e-812d-4841-d5ae-65d78b9a06ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.umfWvzIHqW/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
            "gpg: key DCC9EFBF77E11517: public key \"Debian Stable Release Key (10/buster) <debian-release@lists.debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.LTOQShlU5G/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
            "gpg: key DC30D7C23CBBABEE: public key \"Debian Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.GiZGEZ3D3n/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
            "gpg: key 4DFAB270CAA96DFA: public key \"Debian Security Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "/bin/bash: line 31: warning: here-document at line 23 delimited by end-of-file (wanted `EOF')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up**"
      ],
      "metadata": {
        "id": "ivQ2JXyJ6dla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install -y chromium-chromedriver\n",
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGEowvzef8vQ",
        "outputId": "d3fa43d8-b7cb-47f5-823c-8b208e1ac30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.24.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.8)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading selenium-4.24.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.24.0 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Get:1 http://deb.debian.org/debian buster InRelease [122 kB]\n",
            "Get:2 http://deb.debian.org/debian buster-updates InRelease [56.6 kB]\n",
            "Get:3 http://deb.debian.org/debian-security buster/updates InRelease [34.8 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://deb.debian.org/debian buster/main amd64 Packages [10.7 MB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:8 http://deb.debian.org/debian buster-updates/main amd64 Packages [9,745 B]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:10 http://deb.debian.org/debian-security buster/updates/main amd64 Packages [796 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [57.5 kB]\n",
            "Ign:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,267 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,310 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,114 kB]\n",
            "Hit:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,150 kB]\n",
            "Hit:22 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:23 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,030 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,544 kB]\n",
            "Hit:25 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,439 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Get:28 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,575 kB]\n",
            "Fetched 36.7 MB in 4s (8,332 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools systemd-hwe-hwdb\n",
            "  udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 9 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 28.5 MB of archives.\n",
            "After this operation, 118 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3build2 [595 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.63+22.04ubuntu0.1 [25.9 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 28.5 MB in 4s (6,745 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.3build2_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3build2) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 123805 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.63+22.04ubuntu0.1_amd64.deb ...\n",
            "Unpacking snapd (2.63+22.04ubuntu0.1) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3build2) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service â†’ /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.63+22.04ubuntu0.1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service â†’ /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service â†’ /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service â†’ /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service â†’ /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service â†’ /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service â†’ /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service â†’ /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer â†’ /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket â†’ /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service â†’ /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 124035 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 66 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arguments of Driver Set Up**"
      ],
      "metadata": {
        "id": "MEDWbp5x6eti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# Setup Chrome options for Selenium in Colab\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--disable-gpu')\n",
        "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "\n",
        "# Initialize the Chrome WebDriver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n"
      ],
      "metadata": {
        "id": "8kbXKyB5f3F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single Threaded Approach**"
      ],
      "metadata": {
        "id": "8bNGdMyM6jLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Project: ProConnect360 - Multi-threaded Faculty Profile Scraper\n",
        "\n",
        "Description:\n",
        "This script is designed to scrape personnel profiles, such as faculty or staff members, from a paginated website.\n",
        "The script first collects all profile links from all pages, ensuring comprehensive data collection.\n",
        "It then scrapes each profile using multi-threading, significantly reducing the scraping time.\n",
        "\n",
        "Features:\n",
        "1. Collects all profile links across multiple pages to avoid missing any data due to pagination issues.\n",
        "2. Scrapes detailed profile information, including name, description, employment status, and email.\n",
        "3. Utilizes multi-threading to scrape multiple profiles concurrently, improving efficiency.\n",
        "4. Handles dynamic page navigation using JavaScript execution.\n",
        "5. Includes error handling for robustness and reliability.\n",
        "\n",
        "Modules Used:\n",
        "- Selenium: For browser automation and interaction with web elements.\n",
        "- concurrent.futures: For implementing multi-threading.\n",
        "- time: For adding delays to mimic human behavior and ensure proper page loading.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "\n",
        "# Step 1: Set up Chrome options for headless browsing\n",
        "# This allows the browser to run in the background without opening a GUI, improving speed and efficiency.\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--no-sandbox')  # Disable sandbox for compatibility\n",
        "chrome_options.add_argument('--headless')  # Enable headless mode\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # Avoid shared memory issues\n",
        "chrome_options.add_argument('--disable-gpu')  # Disable GPU for better performance in headless mode\n",
        "\n",
        "# Initialize the WebDriver for the main scraping workflow\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Function to scrape a single staff profile\n",
        "def scrape_staff_profile(profile_url):\n",
        "    \"\"\"\n",
        "    Scrapes detailed information from a single profile page.\n",
        "\n",
        "    Args:\n",
        "        profile_url (str): URL of the individual profile page.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the scraped profile data.\n",
        "    \"\"\"\n",
        "    # Each thread initializes its own WebDriver instance\n",
        "    local_driver = webdriver.Chrome(options=chrome_options)\n",
        "    local_driver.get(profile_url)\n",
        "    time.sleep(2)  # Wait for the page to fully load\n",
        "\n",
        "    staff_data = {}\n",
        "\n",
        "    try:\n",
        "        # Extract profile details\n",
        "        staff_data['url'] = profile_url\n",
        "        staff_data['name'] = local_driver.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "        staff_data['description'] = local_driver.find_element(By.CSS_SELECTOR, \".title.mb-3 span\").text\n",
        "        staff_data['employment_status'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-solid.fa-circle-dashed + span\").text\n",
        "        staff_data['status'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-user-tie + span\").text\n",
        "        staff_data['email'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-envelope + span\").text\n",
        "    except Exception as e:\n",
        "        # Log errors during profile scraping\n",
        "        print(f\"Error extracting data from {profile_url}: {str(e)}\")\n",
        "    finally:\n",
        "        # Quit the local WebDriver instance to release resources\n",
        "        local_driver.quit()\n",
        "\n",
        "    return staff_data\n",
        "\n",
        "# Function to scrape profile links from the current page\n",
        "def scrape_profile_links():\n",
        "    \"\"\"\n",
        "    Scrapes all profile links from the current page.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of profile URLs found on the page.\n",
        "    \"\"\"\n",
        "    time.sleep(2)  # Wait for the page to fully load\n",
        "    profiles = driver.find_elements(By.CSS_SELECTOR, \".faculty_block a\")  # Locate profile links\n",
        "    return [profile.get_attribute(\"href\") for profile in profiles]\n",
        "\n",
        "# Function to scrape all pages and collect profile links\n",
        "def scrape_all_pages():\n",
        "    \"\"\"\n",
        "    Collects all profile links across multiple pages.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of all profile URLs collected from all pages.\n",
        "    \"\"\"\n",
        "    all_profiles = []  # Initialize an empty list for storing all profile links\n",
        "    page_number = 1  # Start with the first page\n",
        "\n",
        "    while True:\n",
        "        print(f\"Scraping page {page_number} for profile links...\")\n",
        "        profile_links = scrape_profile_links()\n",
        "\n",
        "        # Break the loop if no profiles are found on the current page\n",
        "        if not profile_links:\n",
        "            break\n",
        "\n",
        "        all_profiles.extend(profile_links)  # Add the links to the main list\n",
        "\n",
        "        # Navigate to the next page using JavaScript (adjust based on site structure)\n",
        "        try:\n",
        "            driver.execute_script(f\"staff({page_number})\")  # Simulate pagination\n",
        "            page_number += 1\n",
        "            time.sleep(5)  # Wait for the next page to load\n",
        "        except Exception as e:\n",
        "            print(f\"Error navigating to page {page_number}: {e}\")\n",
        "            break\n",
        "\n",
        "    return all_profiles\n",
        "\n",
        "# Function to scrape profiles using multi-threading\n",
        "def scrape_profiles_with_threads(profile_urls):\n",
        "    \"\"\"\n",
        "    Scrapes multiple profiles concurrently using multi-threading.\n",
        "\n",
        "    Args:\n",
        "        profile_urls (list): List of profile URLs to scrape.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries containing the scraped profile data.\n",
        "    \"\"\"\n",
        "    results = []  # Initialize a list to store the results\n",
        "\n",
        "    # Use ThreadPoolExecutor to handle multi-threaded scraping\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers as needed\n",
        "        future_to_url = {executor.submit(scrape_staff_profile, url): url for url in profile_urls}\n",
        "\n",
        "        # Process completed tasks as they finish\n",
        "        for future in as_completed(future_to_url):\n",
        "            url = future_to_url[future]\n",
        "            try:\n",
        "                data = future.result()\n",
        "                if data:\n",
        "                    results.append(data)  # Append the scraped data to the results list\n",
        "                    print(f\"Scraped: {data['name']} from {url}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in thread for {url}: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Main function to control the scraping workflow\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrates the scraping workflow by collecting profile links,\n",
        "    scraping data concurrently, and printing the results.\n",
        "    \"\"\"\n",
        "    # Load the main website\n",
        "    url = \"https://www.uet.edu.pk/academics/staff/faculty-members\"\n",
        "    driver.get(url)\n",
        "    time.sleep(2)  # Wait for the page to load\n",
        "\n",
        "    # Scrape all profile links from all pages\n",
        "    profile_links = scrape_all_pages()\n",
        "\n",
        "    if profile_links:\n",
        "        print(f\"Found {len(profile_links)} profiles to scrape.\")\n",
        "\n",
        "        # Use multi-threading to scrape profiles\n",
        "        scraped_data = scrape_profiles_with_threads(profile_links)\n",
        "\n",
        "        # Print the scraped data\n",
        "        for data in scraped_data:\n",
        "            print(f\"Name: {data['name']}, Description: {data['description']}, Employment Status: {data['employment_status']}, Status: {data['status']}, Email: {data['email']}\")\n",
        "    else:\n",
        "        print(\"No profiles found.\")\n",
        "\n",
        "    # Close the main WebDriver\n",
        "    driver.quit()\n",
        "\n",
        "# Entry point for the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "KQeb7LMrnvn3",
        "outputId": "29f39162-3419-4879-c411-1dc84a8f18dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "Scraping page 2...\n",
            "Scraping page 3...\n",
            "Scraping page 4...\n",
            "Scraping page 5...\n",
            "Scraping page 6...\n",
            "Scraping page 7...\n",
            "Scraping page 8...\n",
            "Scraping page 9...\n",
            "Scraping page 10...\n",
            "Scraping page 11...\n",
            "Scraping page 12...\n",
            "Scraping page 13...\n",
            "Scraping page 14...\n",
            "Scraping page 15...\n",
            "Scraping page 16...\n",
            "Scraping page 17...\n",
            "Scraping page 18...\n",
            "Scraping page 19...\n",
            "Scraping page 20...\n",
            "Scraping page 21...\n",
            "Scraping page 22...\n",
            "Scraping page 23...\n",
            "Scraping page 24...\n",
            "Scraping page 25...\n",
            "Scraping page 26...\n",
            "Scraping page 27...\n",
            "Scraping page 28...\n",
            "Scraping page 29...\n",
            "Scraping page 30...\n",
            "Scraping page 31...\n",
            "Scraping page 32...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-8b4d8199ad6d>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-8b4d8199ad6d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Scrape all profile links from all pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mprofile_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_all_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprofile_links\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8b4d8199ad6d>\u001b[0m in \u001b[0;36mscrape_all_pages\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Scraping page {page_number}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mprofile_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_profile_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# If no profile links are found, we assume there are no more pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8b4d8199ad6d>\u001b[0m in \u001b[0;36mscrape_profile_links\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Function to scrape the profile links from the current page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_profile_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for the page to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprofiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".faculty_block a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprofile_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprofile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprofiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi Threaded Approach**\n"
      ],
      "metadata": {
        "id": "oXdzBFw06s_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Project: ProConnect360 - Multi-threaded Scraper for Personnel Profiles\n",
        "\n",
        "Description:\n",
        "This script is designed to scrape profiles of personnel (e.g., faculty or staff) from a paginated website.\n",
        "It uses multi-threading to scrape multiple profiles concurrently, significantly reducing the total execution time.\n",
        "The script extracts details such as names, descriptions, employment status, and emails for analysis or record-keeping.\n",
        "\n",
        "Features:\n",
        "1. Scrapes profile data from all pages dynamically.\n",
        "2. Utilizes multi-threading to handle concurrent scraping tasks efficiently.\n",
        "3. Extracts detailed information, including URLs, names, descriptions, and contact details.\n",
        "4. Includes robust error handling for thread safety and resilience.\n",
        "5. Designed to maximize resource utilization and minimize scraping time for large datasets.\n",
        "\n",
        "Modules Used:\n",
        "- Selenium: For web automation and interaction with dynamic web elements.\n",
        "- concurrent.futures: For multi-threading to improve scraping efficiency.\n",
        "- time: For managing delays and simulating human-like interactions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "\n",
        "# Step 1: Configure Chrome options for headless browsing\n",
        "# Headless mode allows the browser to operate without a graphical user interface.\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--no-sandbox')  # Disable sandbox for compatibility\n",
        "chrome_options.add_argument('--headless')  # Enable headless mode for faster execution\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # Avoid shared memory issues\n",
        "chrome_options.add_argument('--disable-gpu')  # Disable GPU rendering for headless mode\n",
        "\n",
        "# Initialize the WebDriver for primary navigation\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Function to scrape a single staff profile\n",
        "def scrape_staff_profile(profile_url):\n",
        "    \"\"\"\n",
        "    Scrapes detailed information from an individual profile page.\n",
        "\n",
        "    Args:\n",
        "        profile_url (str): URL of the profile to scrape.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the scraped profile details.\n",
        "    \"\"\"\n",
        "    # Each thread uses a separate WebDriver instance\n",
        "    local_driver = webdriver.Chrome(options=chrome_options)\n",
        "    local_driver.get(profile_url)\n",
        "    time.sleep(2)  # Wait for the page to load completely\n",
        "\n",
        "    staff_data = {}\n",
        "\n",
        "    try:\n",
        "        # Extract details from the profile page\n",
        "        staff_data['url'] = profile_url\n",
        "        staff_data['name'] = local_driver.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "        staff_data['description'] = local_driver.find_element(By.CSS_SELECTOR, \".title.mb-3 span\").text\n",
        "        staff_data['employment_status'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-solid.fa-circle-dashed + span\").text\n",
        "        staff_data['status'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-user-tie + span\").text\n",
        "        staff_data['email'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-envelope + span\").text\n",
        "\n",
        "        # Print extracted data for debugging\n",
        "        print(f\"\\nScraped Profile:\\nURL: {staff_data['url']}\\nName: {staff_data['name']}\\nDescription: {staff_data['description']}\\nEmployment Status: {staff_data['employment_status']}\\nStatus: {staff_data['status']}\\nEmail: {staff_data['email']}\")\n",
        "    except Exception as e:\n",
        "        # Handle errors and log the issue\n",
        "        print(f\"Error extracting data from {profile_url}: {str(e)}\")\n",
        "    finally:\n",
        "        # Close the WebDriver instance to free up resources\n",
        "        local_driver.quit()\n",
        "\n",
        "    return staff_data\n",
        "\n",
        "# Function to scrape profile links from the current page\n",
        "def scrape_profile_links():\n",
        "    \"\"\"\n",
        "    Scrapes all profile links from the current page.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of profile URLs found on the page.\n",
        "    \"\"\"\n",
        "    time.sleep(2)  # Ensure the page has fully loaded\n",
        "    profiles = driver.find_elements(By.CSS_SELECTOR, \".faculty_block a\")  # Locate profile links\n",
        "    return [profile.get_attribute(\"href\") for profile in profiles]\n",
        "\n",
        "# Function to dynamically scrape all pages and dispatch tasks\n",
        "def scrape_all_pages_with_threads():\n",
        "    \"\"\"\n",
        "    Scrapes profile links from all pages and processes them using multi-threading.\n",
        "    \"\"\"\n",
        "    page_number = 1  # Start with the first page\n",
        "\n",
        "    # Use ThreadPoolExecutor for concurrent scraping\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        futures = []  # List to store future tasks\n",
        "\n",
        "        while True:\n",
        "            print(f\"Scraping page {page_number} for URLs...\")\n",
        "\n",
        "            # Extract profile links from the current page\n",
        "            profile_links = scrape_profile_links()\n",
        "\n",
        "            # Break if no profiles are found, indicating the end of pages\n",
        "            if not profile_links:\n",
        "                break\n",
        "\n",
        "            # Submit scraping tasks for each profile link\n",
        "            for link in profile_links:\n",
        "                futures.append(executor.submit(scrape_staff_profile, link))\n",
        "\n",
        "            # Navigate to the next page if available\n",
        "            try:\n",
        "                driver.execute_script(f\"staff({page_number})\")  # Simulate pagination\n",
        "                page_number += 1\n",
        "                time.sleep(5)  # Allow time for the next page to load\n",
        "            except Exception as e:\n",
        "                print(f\"Error navigating to page {page_number}: {e}\")\n",
        "                break\n",
        "\n",
        "        # Wait for all scraping tasks to complete\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                # Get the result of the scraping task\n",
        "                data = future.result()\n",
        "                # Handle or store the data as needed\n",
        "            except Exception as e:\n",
        "                print(f\"Error in a thread: {e}\")\n",
        "\n",
        "# Main function to control the workflow\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrates the scraping process by loading the main site,\n",
        "    scraping profile links, and processing the profiles using threads.\n",
        "    \"\"\"\n",
        "    # Load the website to scrape\n",
        "    url = \"https://www.uet.edu.pk/academics/staff/faculty-members\"\n",
        "    driver.get(url)\n",
        "    time.sleep(2)  # Wait for the initial page to load\n",
        "\n",
        "    # Start scraping pages and profiles using threads\n",
        "    scrape_all_pages_with_threads()\n",
        "\n",
        "    # Close the primary WebDriver instance\n",
        "    driver.quit()\n",
        "\n",
        "# Entry point for the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tmmg2gEHuJyG",
        "outputId": "73eb86a4-4bd7-47b6-b337-30395bf222d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1 for URLs...\n",
            "Scraping page 2 for URLs...\n",
            "Scraping page 3 for URLs...\n",
            "Scraping page 4 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/8\n",
            "Name: Dr. Khurram Rashid\n",
            "Description: Professor at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: khuram_ae@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/17\n",
            "Name: Mr. Jawad Ahamd Tahir\n",
            "Description: Assistant Professor at Department of Architecture, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/16\n",
            "Name: Dr. Malik Usman Mehmood Awan\n",
            "Description: Assistant Professor at Department of Architecture, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: usmanawan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/5\n",
            "Name: Mr. Imran Ahmad Saeed.\n",
            "Description: Assistant Professor at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: is_uet@yahoo.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/9\n",
            "Name: Dr. Nasir Javed\n",
            "Description: Lecturer at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: nasirjaved@uet.edu.pk\n",
            "Scraping page 5 for URLs...\n",
            "Scraping page 6 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/18\n",
            "Name: Mr. Muhammad Saad Khan\n",
            "Description: Assistant Professor at Department of Architecture, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/29\n",
            "Name: Mr. Zaka Ur Rehman Qazi\n",
            "Description: Assistant Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/27\n",
            "Name: Prof. Dr. -Ing. Naveed Ramzan\n",
            "Description: Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: drnramzan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/30\n",
            "Name: Dr. Humayun Wali\n",
            "Description: Assistant Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hwali@uet.edu.pk\n",
            "Scraping page 7 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/32\n",
            "Name: Dr. Muhammad Faheem\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: faheem@uet.edu.pk\n",
            "Scraping page 8 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/35\n",
            "Name: Dr. Hafiz Muhammad Zaheer Aslam\n",
            "Description: Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hmzaheer@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/38\n",
            "Name: Mr. Farhan Ahmad\n",
            "Description: Assistant Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: farhanahmad@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/37\n",
            "Name: Dr. Usman Ali\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: usmanali@uet.edu.pk\n",
            "Scraping page 9 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/39\n",
            "Name: Dr. Muhammad Asif Akhtar\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: imasif@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/36\n",
            "Name: Dr. Umair Aslam\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: umairaslam@uet.edu.pk\n",
            "Scraping page 10 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/5\n",
            "Name: Mr. Imran Ahmad Saeed.\n",
            "Description: Assistant Professor at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: is_uet@yahoo.com\n",
            "Scraping page 11 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/8\n",
            "Name: Dr. Khurram Rashid\n",
            "Description: Professor at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: khuram_ae@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/9\n",
            "Name: Dr. Nasir Javed\n",
            "Description: Lecturer at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: nasirjaved@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/17\n",
            "Name: Mr. Jawad Ahamd Tahir\n",
            "Description: Assistant Professor at Department of Architecture, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/16\n",
            "Name: Dr. Malik Usman Mehmood Awan\n",
            "Description: Assistant Professor at Department of Architecture, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: usmanawan@uet.edu.pk\n",
            "Scraping page 12 for URLs...\n",
            "Scraping page 13 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/29\n",
            "Name: Mr. Zaka Ur Rehman Qazi\n",
            "Description: Assistant Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/27\n",
            "Name: Prof. Dr. -Ing. Naveed Ramzan\n",
            "Description: Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: drnramzan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/18\n",
            "Name: Mr. Muhammad Saad Khan\n",
            "Description: Assistant Professor at Department of Architecture, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/32\n",
            "Name: Dr. Muhammad Faheem\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: faheem@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/30\n",
            "Name: Dr. Humayun Wali\n",
            "Description: Assistant Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hwali@uet.edu.pk\n",
            "Scraping page 14 for URLs...\n",
            "Scraping page 15 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/35\n",
            "Name: Dr. Hafiz Muhammad Zaheer Aslam\n",
            "Description: Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hmzaheer@uet.edu.pk\n",
            "Scraping page 16 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/36\n",
            "Name: Dr. Umair Aslam\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: umairaslam@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/39\n",
            "Name: Dr. Muhammad Asif Akhtar\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: imasif@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/37\n",
            "Name: Dr. Usman Ali\n",
            "Description: Associate Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: usmanali@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/38\n",
            "Name: Mr. Farhan Ahmad\n",
            "Description: Assistant Professor at Department of Chemical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: farhanahmad@uet.edu.pk\n",
            "Scraping page 17 for URLs...\n",
            "Scraping page 18 for URLs...\n",
            "Scraping page 19 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/44\n",
            "Name: Dr. Humayun Ajaz\n",
            "Description: Associate Professor at Department of Chemistry, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: humayunajaz@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/47\n",
            "Name: Dr. Abdul Ghaffar\n",
            "Description: Assistant Professor at Department of Chemistry, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: abdul.ghaffar@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/51\n",
            "Name: Prof. Dr. Rizwan Hameed\n",
            "Description: Professor at Department of City And Regional Planning , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: drrizwanhameed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/52\n",
            "Name: Dr. Obaidullah Nadeem\n",
            "Description: Professor at Department of City And Regional Planning , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: obaidnadeem@uet.edu.pk\n",
            "Scraping page 20 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/53\n",
            "Name: Dr. Ijaz Ahmad\n",
            "Description: Professor at Department of City And Regional Planning , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: haamsafar@hotmail,com\n",
            "Scraping page 21 for URLs...\n",
            "Scraping page 22 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/54\n",
            "Name: Dr. Shaker Mahmood Mayo\n",
            "Description: Professor at Department of City And Regional Planning , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: plannershaker@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/57\n",
            "Name: Prof. Dr. Amer Aziz\n",
            "Description: Professor at Department of City And Regional Planning , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: dr.ameraziz@gmail.com\n",
            "Scraping page 23 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/56\n",
            "Name: Dr. Muhammad Asim\n",
            "Description: Associate Professor at Department of City And Regional Planning , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: muhammad.asim@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/55\n",
            "Name: Dr.-Ing. Atif Bilal Aslam\n",
            "Description: Associate Professor at Department of Product and Industrial Design , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: atif.aslam@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/65\n",
            "Name: Prof. Dr. Khalid Farooq\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: kfch@uet.edu.pk\n",
            "Scraping page 24 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/70\n",
            "Name: Prof. Dr. Asad Ullah Qazi.\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: asad.qazi@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/71\n",
            "Name: Prof. Dr. Sajjad Mubin\n",
            "Description: Professor at Department of Architectural Engineering & Design, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: sajjadmubin@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/69\n",
            "Name: Prof. Dr. Noor Muhammad Khan.\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: noorkhan@uet.edu.pk\n",
            "Scraping page 25 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/78\n",
            "Name: Dr. Imtiaz Rashid.\n",
            "Description: Assistant Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: imti90@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/72\n",
            "Name: Prof. Dr. Asif Hameed.\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: asifhameed@uet.edu.pk\n",
            "Scraping page 26 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/81\n",
            "Name: Prof. Dr. Muhammad Burhan Sharif.\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: burhansharif@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/82\n",
            "Name: Prof. Dr. Ammad Hassan Khan\n",
            "Description: Professor at Department of Transportation Engineering and Management, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: chair-tem@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/83\n",
            "Name: Dr. Muhammad Azhar Saleem.\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: msale005@fiu.edu\n",
            "Scraping page 27 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/84\n",
            "Name: Dr. Muhammad Irfan-ul-Hassan\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: irfanulhassan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/87\n",
            "Name: Prof. Dr. Rashid Hameed\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: rashidmughal@uet.edu.pk\n",
            "Scraping page 28 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/95\n",
            "Name: Dr. Muhammad Yousaf.\n",
            "Description: Assistant Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: yousaf_dr786@uet.edu.pk\n",
            "Scraping page 29 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/88\n",
            "Name: Dr. Hassan Mujtaba Shahzad.\n",
            "Description: Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hassanmujtaba@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/90\n",
            "Name: Dr. Qasim Shaukat Khan\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: qasimkhan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/103\n",
            "Name: Dr. Usman Akmal\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: usman.akmal@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/105\n",
            "Name: Dr. Rizwan Azam.\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: azam.rizwan@uet.edu.pk\n",
            "Scraping page 30 for URLs...\n",
            "Scraping page 31 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/106\n",
            "Name: Dr. Wasim Abbas\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: wabbass@uet.edu.pk\n",
            "Scraping page 32 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/108\n",
            "Name: Dr. Nauman Khurram\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: nauman (at) uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/107\n",
            "Name: Dr. Safeer Abbas\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: safeer.abbas@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/109\n",
            "Name: Dr. Ali Ahmed\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ali [at] uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/110\n",
            "Name: Dr. Muhammad Mazhar Saleem\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: engrmazhar@uet.edu.pk\n",
            "Scraping page 33 for URLs...\n",
            "Scraping page 34 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/112\n",
            "Name: Engr. Usman Ali\n",
            "Description: Assistant Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: engr.usmanali@uet.edu.pk\n",
            "Scraping page 35 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/113\n",
            "Name: Dr. Jahanzaib Israr\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: jisrar@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/116\n",
            "Name: Dr. Syed Asad Ali Gillani\n",
            "Description: Associate Professor at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: asadgillani@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/117\n",
            "Name: Engr. Muhammad Rehan Ashraf\n",
            "Description: Lecturer at Department of Civil Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: rehanashraf@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/121\n",
            "Name: Prof. Dr. Muhammad Shahbaz\n",
            "Description: Professor at Department of Computer Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: M.Shahbaz-at-uet.edu.pk\n",
            "Scraping page 36 for URLs...\n",
            "Scraping page 37 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/124\n",
            "Name: Prof. Dr. Muhammad Shoaib\n",
            "Description: Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: shoaib@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/125\n",
            "Name: Dr. Irfan Ullah Ch.\n",
            "Description: Associate Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/126\n",
            "Name: Dr. Amjad Farooq\n",
            "Description: Associate Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: amjadfarooq@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/128\n",
            "Name: Dr. Tauqir Ahmad\n",
            "Description: Associate Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: tauqir_ahmad@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/130\n",
            "Name: Dr. Junaid Arshad\n",
            "Description: Associate Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: junaidarshad@uet.edu.pk\n",
            "Scraping page 38 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/131\n",
            "Name: Prof. Dr. Muhammad Aslam\n",
            "Description: Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: maslam@uet.edu.pk\n",
            "Scraping page 39 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/136\n",
            "Name: Dr. Talha Waheed\n",
            "Description: Assistant Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: twaheed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/137\n",
            "Name: Dr. Muhammad Faisal Hayat\n",
            "Description: Associate Professor at Department of Computer Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: muhammad.faisal.hayat@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/138\n",
            "Name: Dr. Yasir Saleem\n",
            "Description: Associate Professor at Department of Computer Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ysaleem@gmail.com; yasir@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/139\n",
            "Name: Prof. Dr. Ali Hammad Akbar\n",
            "Description: Professor at Department of Computer Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: ahakbar@gmail.com\n",
            "Scraping page 40 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/140\n",
            "Name: Dr. Syed Khaldoon Khurshid\n",
            "Description: Associate Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: khaldoon@uet.edu.pk\n",
            "Scraping page 41 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/141\n",
            "Name: Prof. Dr. Hafiz Muhammad Shahzad Asif\n",
            "Description: Professor at Department of Computer Science (New Campus), UET New Campus (KSK)\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: shehzad@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/142\n",
            "Name: Prof. Dr. Muhammad Usman Ghani Khan\n",
            "Description: Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: Usman.ghani@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/143\n",
            "Name: Mr. Asim Rehmat\n",
            "Description: Assistant Professor at Department of Computer Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: asimrehmat@uet.edu.pk\n",
            "Scraping page 42 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/144\n",
            "Name: Dr. Muhammad Awais Hassan\n",
            "Description: Associate Professor at Department of Computer Science, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: awais.hassan@uet.edu.pk\n",
            "Scraping page 43 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/147\n",
            "Name: Fareed Ud Din Mehmood Jafri\n",
            "Description: Assistant Professor at Department of Computer Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: fjafri3@gatech.edu\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/157\n",
            "Name: Dr. Asim Loan\n",
            "Description: Associate Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: aloan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/160\n",
            "Name: Dr. Muhammad Asghar Saqib\n",
            "Description: Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: saqib@uet.edu.pk\n",
            "Scraping page 44 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/161\n",
            "Name: Dr. Muhammad Ali\n",
            "Description: Associate Professor at Department of Electrical, Electronics and Telecommunication Engineering (New Campus) , UET New Campus (KSK)\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: m.ali@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/162\n",
            "Name: Prof. Dr. Kashif Javed\n",
            "Description: Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: kashif.javed@uet.edu.pk\n",
            "Scraping page 45 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/163\n",
            "Name: Prof. Dr. Muhammad Tahir\n",
            "Description: Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mtahir@uet.edu.pk\n",
            "Scraping page 46 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/164\n",
            "Name: Ahsan\n",
            "Description: Associate Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON EOL EX-PAKISTAN\n",
            "Status: Regular\n",
            "Email: ahsan-at-uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/165\n",
            "Name: Dr. Umar Tabraiz Shami\n",
            "Description: Associate Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ushami@ymail.com\n",
            "Scraping page 47 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/171\n",
            "Name: Dr. Syed Shah Irfan Hussain\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ssirfanhussain@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/166\n",
            "Name: Engr.Hafiz Muhammad Suleman\n",
            "Description: Lecturer at Department of Mechanical Engineering RCET, UET Rachna College of Engineering & Technology\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hmsuleman@uet.edu.pk\n",
            "Scraping page 48 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/173\n",
            "Name: Dr. Syed Abdul Rahman Kashif\n",
            "Description: Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: abdulrahman@uet.edu.pk, twaseen786@gmail.com\n",
            "Scraping page 49 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/172\n",
            "Name: Dr. Farhan Mahmood\n",
            "Description: Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: fmahmood@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/175\n",
            "Name: Naveed Nawaz\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: naveed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/177\n",
            "Name: Mr. Omar Lateef\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: \n",
            "Scraping page 50 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/187\n",
            "Name: Dr. Nauman Ahmed\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: nahmed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/196\n",
            "Name: Dr. Farrukh Arslan\n",
            "Description: Assistant Professor at Department of Electrical, Electronics and Telecommunication Engineering (New Campus) , UET New Campus (KSK)\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: farrukh_arslan@uet.edu.pk\n",
            "Scraping page 51 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/201\n",
            "Name: Mr. Arsalan A Rahim\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: arsalanarahim@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/208\n",
            "Name: Engr. Abu Bakar Siddique\n",
            "Description: Lecturer at Department of Electrical Engineering RCET, UET Rachna College of Engineering & Technology\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: abubakar@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/211\n",
            "Name: Mr. Ali Mohsin\n",
            "Description: Lecturer at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: \n",
            "Scraping page 52 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/212\n",
            "Name: Miss Sahar Idrees\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "Scraping page 53 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/215\n",
            "Name: Mr. Muhammad Waseem Arshad\n",
            "Description: Lecturer at Department of Electrical, Electronics and Telecommunication Engineering (FSD Campus), UET Faisalabad Campus\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: waseem.arshad@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/223\n",
            "Name: Mr. Muhammad Bilal\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: m.bilal@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/230\n",
            "Name: Prof. Dr. Muhammad Zubair Abu Bakar\n",
            "Description: Professor at Department of Geological Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mzubairab1977@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/219\n",
            "Name: Dr. Adeem Aslam\n",
            "Description: Assistant Professor at Department of Electrical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: adeem.aslam@uet.edu.pk\n",
            "Scraping page 54 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/232\n",
            "Name: Prof. Dr. Muhammad Farooq Ahmad\n",
            "Description: Professor at Department of Geological Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mfageo@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/234\n",
            "Name: Dr. Muhammad Arshad\n",
            "Description: Assistant Professor at Department of Geological Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: arshadm@uet.edu.pk\n",
            "Scraping page 55 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/235\n",
            "Name: Dr. Muhammad Zaka Emad\n",
            "Description: Associate Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: zaka@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/238\n",
            "Name: Dr. Ghulam Mohyuddin Sohail\n",
            "Description: Associate Professor at Department of Geological Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: gmdsohail@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/237\n",
            "Name: Mr. Sheikh Ahmad Ali\n",
            "Description: Assistant Professor at Department of Geological Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: ahmed.ali@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/239\n",
            "Name: Dr. Muhammad Harris\n",
            "Description: Associate Professor at Department of Industrial and Manufacturing Engineering. RCET, UET Rachna College of Engineering & Technology\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: engr.harris@uet.edu.pk, engr.harris@gmail.com\n",
            "Scraping page 56 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/240\n",
            "Name: Dr. Hafiz Muhammad Awais Rashid\n",
            "Description: Assistant Professor at Department of Geological Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: awais.rashid@uet.edu.pk\n",
            "Scraping page 57 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/250\n",
            "Name: Dr. Asif Mahmood Qureshi\n",
            "Description: Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: asifqureshi1971@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/244\n",
            "Name: Muhammad Ajmal Khurshid\n",
            "Description: Assistant Professor at Department of Humanities, Social Sciences and Modern Languages, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: ajmalkhurshid@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/251\n",
            "Name: Prof. Dr. Muhammad Qaiser Saleem\n",
            "Description: Professor at Department of Industrial & Manufacturing Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: qaiser@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/252\n",
            "Name: Prof. Dr. Amjad Hussain.\n",
            "Description: Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: chamjad@uet.edu.pk\n",
            "Scraping page 58 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/254\n",
            "Name: Dr. Sarmad Ali Khan\n",
            "Description: Associate Professor at Department of Industrial & Manufacturing Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: drsarmad@uet.edu.pk\n",
            "Scraping page 59 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/260\n",
            "Name: Dr. Kashif Ishfaq\n",
            "Description: Associate Professor at Department of Industrial & Manufacturing Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: kashif.ishfaq@uet.edu.pk\n",
            "Scraping page 60 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/256\n",
            "Name: Dr. Syed Farhan Raza\n",
            "Description: Assistant Professor at Department of Industrial & Manufacturing Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: sf.raza@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/264\n",
            "Name: Mr. Adeel Shehzad\n",
            "Description: Lecturer at Automotive Engineering Centre, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: adeel.shehzad@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/262\n",
            "Name: Mr. Muhammad Bilal Arshad\n",
            "Description: Assistant Professor at Department of Industrial & Manufacturing Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: bilal_arshad15@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/265\n",
            "Name: Engr. Omer Asghar\n",
            "Description: Lecturer at Automotive Engineering Centre, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: omer@uet.edu.pk\n",
            "Scraping page 61 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/269\n",
            "Name: Prof. Dr. Sajjad H. Sheikh\n",
            "Description: Professor at Institute of Environmental Engineering and Research , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: sajjad@uet.edu.pk\n",
            "Scraping page 62 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/272\n",
            "Name: Dr. Muhammad Umar Farooq\n",
            "Description: Associate Professor at Institute of Environmental Engineering and Research , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: umarfarooq@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/274\n",
            "Name: Prof. Dr. Amir Ikhlaq\n",
            "Description: Professor at Institute of Environmental Engineering and Research , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: aamirikhlaq@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/275\n",
            "Name: Dr. Muhammad Irfan Jalees\n",
            "Description: Associate Professor at Institute of Environmental Engineering and Research , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: jalees@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/276\n",
            "Name: Dr. Ghulam Hussain\n",
            "Description: Associate Professor at Institute of Environmental Engineering and Research , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ghussain@uet.edu.pk\n",
            "Scraping page 63 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/280\n",
            "Name: Dr. Attiq Ur Rehman\n",
            "Description: Associate Professor at Department of Islamic Studies, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: dratiq@uet.edu.pk\n",
            "Scraping page 64 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/281\n",
            "Name: Prof. Dr. Hafiz Muhammad Shahbaz\n",
            "Description: Professor at Department of Islamic Studies, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/282\n",
            "Name: Dr. Muhammad Nadeem Shah\n",
            "Description: Assistant Professor at Department of Islamic Studies, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: murshiduet@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/286\n",
            "Name: Dr. Muneeb Irshad\n",
            "Description: Assistant Professor at Department of Physics, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: muneeb_irshad@uet.edu.pk\n",
            "Scraping page 65 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/284\n",
            "Name: Dr.Hafiz Zahid Latif\n",
            "Description: Associate Professor at Department of Islamic Studies, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: zahid-latif@uet.edu.pk. hzlatif@gmail.com\n",
            "Scraping page 66 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/287\n",
            "Name: Dr. Haamid Jamil\n",
            "Description: Assistant Professor at Department of Physics, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: hamidjamil@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/295\n",
            "Name: Prof. Dr. Muhammad Mushtaq\n",
            "Description: Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mmushtaq@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/296\n",
            "Name: Dr. Shafiq Ur Rehman\n",
            "Description: Associate Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: srehman@uet.edu.pk\n",
            "Scraping page 67 for URLs...\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/297\n",
            "Name: Dr. Mustafa Habib\n",
            "Description: Associate Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: mustafa@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/298\n",
            "Name: Dr. Muhammad Irfan Qadir\n",
            "Description: Associate Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mirfan@uet.edu.pk, irfanqadir_uet@hotmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/299\n",
            "Name: Dr. Anjum Pervaiz\n",
            "Description: Assistant Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: anjumpervaiz10@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/300\n",
            "Name: Prof. Dr. Sabir Hussain\n",
            "Description: Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: sabirhus@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/302\n",
            "Name: Prof. Dr. Qasim Ali Chaudhry\n",
            "Description: Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: chqasim@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/303\n",
            "Name: Dr. Taimoor Iqbal\n",
            "Description: Assistant Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: taimooriqbal@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/304\n",
            "Name: Dr. Muhammad Shabbir\n",
            "Description: Assistant Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mshabbir@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/306\n",
            "Name: Dr. Ali Ovais\n",
            "Description: Lecturer at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/305\n",
            "Name: Dr. Kashif Ali Khan\n",
            "Description: Assistant Professor at Department of Mathematics , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: kashifali@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/318\n",
            "Name: Prof. Dr. Muhammad Mahmood Aslam Bhutta.\n",
            "Description: Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: drbhutta@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/323\n",
            "Name: Dr. Naseer Ahmad\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: nahmad@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/320\n",
            "Name: Prof. Dr. Asad Naeem Shah\n",
            "Description: Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: anaeems@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/324\n",
            "Name: Mr. Muhammad Rashid Sajid.\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: engrmrsajid@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/325\n",
            "Name: Mr. Shabbir Hussain.\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: shabbir@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/336\n",
            "Name: Mr. Muhammad Kashif Tariq.\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: m.kashif@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/337\n",
            "Name: Mr. Umair Ashraf Khokhar\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: umairashraf@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/338\n",
            "Name: Dr. Fahad Noor\n",
            "Description: Professor at Department of Mechanical, Mechatronics and Manufacturing Engineering (New Campus), UET New Campus (KSK)\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: f.noor@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/341\n",
            "Name: Dr. Muhammad Farhan\n",
            "Description: Associate Professor at Department of Mechanical, Mechatronics and Manufacturing Engineering (New Campus), UET New Campus (KSK)\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: m.farhan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/343\n",
            "Name: Dr. Zia ul Rehman Tahir\n",
            "Description: Associate Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ziartahir@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/344\n",
            "Name: Dr. Zahid Anwar\n",
            "Description: Professor at Department of Mechanical, Mechatronics and Manufacturing Engineering (New Campus), UET New Campus (KSK)\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: zahidanwar@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/347\n",
            "Name: Dr. Muhammad Asim\n",
            "Description: Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: masim381@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/350\n",
            "Name: Dr. Jafar Hussain\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: jafarhussain@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/351\n",
            "Name: Dr. Awais Ahmad Khan\n",
            "Description: Associate Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: awais211@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/353\n",
            "Name: Dr. Muhammad Usman\n",
            "Description: Associate Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: muhammadusman@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/354\n",
            "Name: Mr. Ahmad Naveed\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ahmadnaveed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/355\n",
            "Name: Hafiz Zahid Nabi\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: engrhzahid@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/356\n",
            "Name: Dr. Jamal Umer\n",
            "Description: Associate Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: jamalumer@uet.edu.pk, jamal137@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/357\n",
            "Name: Syed Saqib\n",
            "Description: Assistant Professor at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: syedsaqib@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/360\n",
            "Name: Dr. Ali Hussain Kazim\n",
            "Description: Associate Professor at Automotive Engineering Centre, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ali.h.kazim@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/362\n",
            "Name: Dr. Talha Khan\n",
            "Description: Lecturer at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: talha.khan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/364\n",
            "Name: Mr. Haris Hussain\n",
            "Description: Lecturer at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: \n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/366\n",
            "Name: Syed Wasim Hassan Zubair\n",
            "Description: Lecturer at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: syedwasim@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/367\n",
            "Name: Mr. Muhammad Imran Masood\n",
            "Description: Lecturer at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: mimran.masood@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/368\n",
            "Name: Mr. Muhammad Tahir Ameen\n",
            "Description: Lecturer at Department of Mechanical Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: tahir.ameen@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/372\n",
            "Name: Dr. Ali Raza\n",
            "Description: Associate Professor at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: ali.raza@ymail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/376\n",
            "Name: Mr. Adnan Rauf\n",
            "Description: Assistant Professor at Department of Bio-Medical Centre (NewCampus), UET New Campus (KSK)\n",
            "Employment Status: ON DUTY\n",
            "Status: Short Term Contract\n",
            "Email: adnan.rauf@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/378\n",
            "Name: Ms. Maliha Saleem Bakhshi\n",
            "Description: Assistant Professor at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: maliha.bakhshi@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/383\n",
            "Name: Dr. Syed Abbas Zilqurnain Naqvi.\n",
            "Description: Associate Professor at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: sazn26@gmail.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/384\n",
            "Name: Dr. Muhammad Ahsan\n",
            "Description: Associate Professor at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Tenure Track\n",
            "Email: m.ahsan@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/385\n",
            "Name: Moaaz Rauf Nizami\n",
            "Description: Lecturer at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: moaaz@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/388\n",
            "Name: Mr. Muhammad Rzi Abbas\n",
            "Description: Lecturer at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: muhammadrziabbas@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/386\n",
            "Name: Dr. Muhammad Ahsan Naeem\n",
            "Description: Assistant Professor at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: mahsan.naeem@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/389\n",
            "Name: Mr. Misbah Ur Rehman\n",
            "Description: Lecturer at Department of Mechatronics & Control Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: misbah@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/402\n",
            "Name: Prof. Dr.-Ing. Furqan Ahmed\n",
            "Description: Professor at Department of Metallurgical & Materials Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: furqan.ahmed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/403\n",
            "Name: Prof. Dr. Muhammad Asif Rafiq\n",
            "Description: Professor at Department of Metallurgical & Materials Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: asifrafiq@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/411\n",
            "Name: Engr. Dr. Yasir Majeed\n",
            "Description: Associate Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: yasirbinmajeed@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/405\n",
            "Name: Mr. Amjad Ali\n",
            "Description: Lecturer at Department of Metallurgical & Materials Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: amjad207eb@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/408\n",
            "Name: Dr.-Ing. Muhammad Zubair\n",
            "Description: Assistant Professor at Department of Metallurgical & Materials Engineering, Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: zubair@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/413\n",
            "Name: Dr.Shahab Saqib\n",
            "Description: Associate Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: Shahab@uet.edu.Pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/414\n",
            "Name: Dr. Muhammad Azeem Raza\n",
            "Description: Assistant Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: azeem@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/415\n",
            "Name: Prof. Dr. Zulfiqar Ali\n",
            "Description: Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: zulfiqar@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/421\n",
            "Name: Muhammad Shahzad\n",
            "Description: Assistant Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: m.shahzad87@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/420\n",
            "Name: Mr. Muhammad Waqas\n",
            "Description: Assistant Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON STUDY LEAVE\n",
            "Status: Regular\n",
            "Email: mwaqas@uet.edu.pk\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/422\n",
            "Name: Mr. Muhammad Badar Hayat\n",
            "Description: Assistant Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: badarhayat@yahoo.com\n",
            "\n",
            "Scraped Profile: \n",
            "URL: https://staff.uet.edu.pk/profile/423\n",
            "Name: Dr. Muhammad Usman Khan\n",
            "Description: Assistant Professor at Department of Mining Engineering , Main Campus UET Lahore\n",
            "Employment Status: ON DUTY\n",
            "Status: Regular\n",
            "Email: usman@uet.edu.pk; meet4khan@gmail.com\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /session/dcb77663b40cd140d4a526d0b95b5e26/element/f.DA99E98C9E3D7828DC8A4610B9C69C81.d.FF8D1A80B9020C046A5492DF3F745F9C.e.12/text\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcbcc1620b0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/dcb77663b40cd140d4a526d0b95b5e26/element/f.DA99E98C9E3D7828DC8A4610B9C69C81.d.FF8D1A80B9020C046A5492DF3F745F9C.e.12/text\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcbccbe2410>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/dcb77663b40cd140d4a526d0b95b5e26/element/f.DA99E98C9E3D7828DC8A4610B9C69C81.d.FF8D1A80B9020C046A5492DF3F745F9C.e.12/text\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcbcc160f40>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/dcb77663b40cd140d4a526d0b95b5e26\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcbccbe0730>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/dcb77663b40cd140d4a526d0b95b5e26\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcbccbe17e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/dcb77663b40cd140d4a526d0b95b5e26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error extracting data from https://staff.uet.edu.pk/profile/428: HTTPConnectionPool(host='localhost', port=59309): Max retries exceeded with url: /session/dcb77663b40cd140d4a526d0b95b5e26/element/f.DA99E98C9E3D7828DC8A4610B9C69C81.d.FF8D1A80B9020C046A5492DF3F745F9C.e.12/text (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcbcc160ca0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d79313fd1bd8>\u001b[0m in \u001b[0;36mscrape_all_pages_with_threads\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Wait for all profile scraping tasks to complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d79313fd1bd8>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d79313fd1bd8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Start scraping all pages and dispatching threads for profile scraping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mscrape_all_pages_with_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Close the main WebDriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d79313fd1bd8>\u001b[0m in \u001b[0;36mscrape_all_pages_with_threads\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# ThreadPoolExecutor for concurrent scraping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question no 3**\n",
        "\n"
      ],
      "metadata": {
        "id": "nS-SlNmI6xFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Project: ProConnect360 - Multi-threaded Scraper with CSV Export\n",
        "\n",
        "Description:\n",
        "This script scrapes personnel profiles from a paginated website using Selenium and saves the data in a CSV file.\n",
        "It utilizes multi-threading to scrape multiple profiles concurrently, significantly reducing execution time.\n",
        "The script dynamically navigates pages, extracts profile links, and gathers details like names, descriptions,\n",
        "employment status, and emails.\n",
        "\n",
        "Features:\n",
        "1. Dynamically scrapes all pages to collect profile links and processes profiles concurrently.\n",
        "2. Extracts details such as names, descriptions, employment status, and contact emails.\n",
        "3. Uses multi-threading for efficient data scraping across multiple profiles.\n",
        "4. Saves the scraped data into a structured CSV format for analysis or sharing.\n",
        "5. Includes error handling for resilient and robust scraping.\n",
        "\n",
        "Modules Used:\n",
        "- Selenium: For web automation and interaction with dynamic web elements.\n",
        "- concurrent.futures: For multi-threading to handle tasks concurrently.\n",
        "- pandas: For organizing and saving the scraped data in a CSV file.\n",
        "- time: For managing delays to ensure proper page loading and mimic human-like behavior.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import pandas as pd  # Used for saving data to CSV\n",
        "import time\n",
        "\n",
        "# Step 1: Configure Chrome options for headless browsing\n",
        "# Headless mode allows for running the browser without a GUI, improving speed and resource usage.\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--no-sandbox')  # Disable sandbox for compatibility\n",
        "chrome_options.add_argument('--headless')  # Enable headless mode for faster execution\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # Avoid shared memory issues\n",
        "chrome_options.add_argument('--disable-gpu')  # Disable GPU rendering in headless mode\n",
        "\n",
        "# Initialize the WebDriver for primary navigation\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Initialize a list to store all scraped profile data\n",
        "all_scraped_data = []\n",
        "\n",
        "# Function to scrape a single staff profile\n",
        "def scrape_staff_profile(profile_url):\n",
        "    \"\"\"\n",
        "    Scrapes detailed information from an individual profile page.\n",
        "\n",
        "    Args:\n",
        "        profile_url (str): URL of the profile to scrape.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the scraped profile details.\n",
        "    \"\"\"\n",
        "    # Each thread initializes its own WebDriver instance\n",
        "    local_driver = webdriver.Chrome(options=chrome_options)\n",
        "    local_driver.get(profile_url)\n",
        "    time.sleep(2)  # Wait for the page to fully load\n",
        "\n",
        "    staff_data = {}\n",
        "\n",
        "    try:\n",
        "        # Extract details from the profile page\n",
        "        staff_data['url'] = profile_url\n",
        "        staff_data['name'] = local_driver.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "        staff_data['description'] = local_driver.find_element(By.CSS_SELECTOR, \".title.mb-3 span\").text\n",
        "        staff_data['employment_status'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-solid.fa-circle-dashed + span\").text\n",
        "        staff_data['status'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-user-tie + span\").text\n",
        "        staff_data['email'] = local_driver.find_element(By.CSS_SELECTOR, \".fa-envelope + span\").text\n",
        "    except Exception as e:\n",
        "        # Log any errors encountered while scraping\n",
        "        print(f\"Error extracting data from {profile_url}: {str(e)}\")\n",
        "    finally:\n",
        "        # Quit the WebDriver instance to release resources\n",
        "        local_driver.quit()\n",
        "\n",
        "    return staff_data\n",
        "\n",
        "# Function to scrape profile links from the current page\n",
        "def scrape_profile_links():\n",
        "    \"\"\"\n",
        "    Scrapes all profile links from the current page.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of profile URLs found on the page.\n",
        "    \"\"\"\n",
        "    time.sleep(2)  # Wait for the page to fully load\n",
        "    profiles = driver.find_elements(By.CSS_SELECTOR, \".faculty_block a\")  # Locate profile links\n",
        "    return [profile.get_attribute(\"href\") for profile in profiles]\n",
        "\n",
        "# Function to scrape all pages and dispatch scraping tasks\n",
        "def scrape_all_pages_with_threads():\n",
        "    \"\"\"\n",
        "    Scrapes profile links from all pages and processes them using multi-threading.\n",
        "    \"\"\"\n",
        "    page_number = 1  # Start with the first page\n",
        "\n",
        "    # Use ThreadPoolExecutor for concurrent scraping\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers for optimal performance\n",
        "        futures = []  # List to store future tasks\n",
        "\n",
        "        while True:\n",
        "            print(f\"Scraping page {page_number} for URLs...\")\n",
        "\n",
        "            # Extract profile links from the current page\n",
        "            profile_links = scrape_profile_links()\n",
        "\n",
        "            # Break if no profiles are found, indicating the end of pages\n",
        "            if not profile_links:\n",
        "                break\n",
        "\n",
        "            # Submit scraping tasks for each profile link\n",
        "            for link in profile_links:\n",
        "                futures.append(executor.submit(scrape_staff_profile, link))\n",
        "\n",
        "            # Navigate to the next page if available\n",
        "            try:\n",
        "                driver.execute_script(f\"staff({page_number})\")  # Simulate pagination using JavaScript\n",
        "                page_number += 1\n",
        "                time.sleep(5)  # Allow time for the next page to load\n",
        "            except Exception as e:\n",
        "                print(f\"Error navigating to page {page_number}: {e}\")\n",
        "                break\n",
        "\n",
        "        # Wait for all scraping tasks to complete\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                # Get the result of the scraping task\n",
        "                data = future.result()\n",
        "                if data:\n",
        "                    all_scraped_data.append(data)  # Append the data to the results list\n",
        "            except Exception as e:\n",
        "                print(f\"Error in a thread: {e}\")\n",
        "\n",
        "# Main function to control the workflow\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrates the scraping process by loading the website,\n",
        "    scraping profile links, and processing profiles using threads.\n",
        "    \"\"\"\n",
        "    # Load the main website\n",
        "    url = \"https://www.uet.edu.pk/academics/staff/faculty-members\"\n",
        "    driver.get(url)\n",
        "    time.sleep(2)  # Wait for the initial page to load\n",
        "\n",
        "    # Start scraping pages and profiles\n",
        "    scrape_all_pages_with_threads()\n",
        "\n",
        "    # Close the primary WebDriver instance\n",
        "    driver.quit()\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "    df = pd.DataFrame(all_scraped_data)\n",
        "\n",
        "    # Save the scraped data to a CSV file\n",
        "    df.to_csv(\"scraped_profiles.csv\", index=False)  # index=False to exclude row numbers in the CSV\n",
        "\n",
        "    print(\"Data has been saved to 'scraped_profiles.csv'\")\n",
        "\n",
        "# Entry point for the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "BWcc_p1UzGCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf701d7-8596-4cc0-865b-8b647a3e30eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1 for URLs...\n",
            "Scraping page 2 for URLs...\n",
            "Scraping page 3 for URLs...\n",
            "Scraping page 4 for URLs...\n",
            "Scraping page 5 for URLs...\n",
            "Scraping page 6 for URLs...\n",
            "Scraping page 7 for URLs...\n",
            "Scraping page 8 for URLs...\n",
            "Scraping page 9 for URLs...\n",
            "Scraping page 10 for URLs...\n",
            "Scraping page 11 for URLs...\n",
            "Scraping page 12 for URLs...\n",
            "Scraping page 13 for URLs...\n",
            "Scraping page 14 for URLs...\n",
            "Scraping page 15 for URLs...\n",
            "Scraping page 16 for URLs...\n",
            "Scraping page 17 for URLs...\n",
            "Scraping page 18 for URLs...\n",
            "Scraping page 19 for URLs...\n",
            "Scraping page 20 for URLs...\n",
            "Scraping page 21 for URLs...\n",
            "Scraping page 22 for URLs...\n",
            "Scraping page 23 for URLs...\n",
            "Scraping page 24 for URLs...\n",
            "Scraping page 25 for URLs...\n",
            "Scraping page 26 for URLs...\n",
            "Scraping page 27 for URLs...\n",
            "Scraping page 28 for URLs...\n",
            "Scraping page 29 for URLs...\n",
            "Scraping page 30 for URLs...\n",
            "Scraping page 31 for URLs...\n",
            "Scraping page 32 for URLs...\n",
            "Scraping page 33 for URLs...\n",
            "Scraping page 34 for URLs...\n",
            "Scraping page 35 for URLs...\n",
            "Scraping page 36 for URLs...\n",
            "Scraping page 37 for URLs...\n",
            "Scraping page 38 for URLs...\n",
            "Scraping page 39 for URLs...\n",
            "Scraping page 40 for URLs...\n",
            "Scraping page 41 for URLs...\n",
            "Scraping page 42 for URLs...\n",
            "Scraping page 43 for URLs...\n",
            "Scraping page 44 for URLs...\n",
            "Scraping page 45 for URLs...\n",
            "Scraping page 46 for URLs...\n",
            "Scraping page 47 for URLs...\n",
            "Scraping page 48 for URLs...\n",
            "Scraping page 49 for URLs...\n",
            "Scraping page 50 for URLs...\n",
            "Scraping page 51 for URLs...\n",
            "Scraping page 52 for URLs...\n",
            "Scraping page 53 for URLs...\n",
            "Scraping page 54 for URLs...\n",
            "Scraping page 55 for URLs...\n",
            "Scraping page 56 for URLs...\n",
            "Scraping page 57 for URLs...\n",
            "Scraping page 58 for URLs...\n",
            "Scraping page 59 for URLs...\n",
            "Scraping page 60 for URLs...\n",
            "Scraping page 61 for URLs...\n",
            "Scraping page 62 for URLs...\n",
            "Scraping page 63 for URLs...\n",
            "Scraping page 64 for URLs...\n",
            "Scraping page 65 for URLs...\n",
            "Scraping page 66 for URLs...\n",
            "Scraping page 67 for URLs...\n",
            "Error in a thread: Message: timeout: Timed out receiving message from renderer: 298.764\n",
            "  (Session info: chrome=128.0.6613.137)\n",
            "Stacktrace:\n",
            "#0 0x556e128742da <unknown>\n",
            "#1 0x556e12542200 <unknown>\n",
            "#2 0x556e1252a1c0 <unknown>\n",
            "#3 0x556e12529ead <unknown>\n",
            "#4 0x556e12527eb8 <unknown>\n",
            "#5 0x556e125286bf <unknown>\n",
            "#6 0x556e125381eb <unknown>\n",
            "#7 0x556e1254e5e4 <unknown>\n",
            "#8 0x556e12553b1b <unknown>\n",
            "#9 0x556e12528dce <unknown>\n",
            "#10 0x556e1254e43f <unknown>\n",
            "#11 0x556e125d5062 <unknown>\n",
            "#12 0x556e125b6673 <unknown>\n",
            "#13 0x556e12584473 <unknown>\n",
            "#14 0x556e1258547e <unknown>\n",
            "#15 0x556e1283b0db <unknown>\n",
            "#16 0x556e1283f071 <unknown>\n",
            "#17 0x556e128279d5 <unknown>\n",
            "#18 0x556e1283fbf2 <unknown>\n",
            "#19 0x556e1280cb6f <unknown>\n",
            "#20 0x556e12863248 <unknown>\n",
            "#21 0x556e12863417 <unknown>\n",
            "#22 0x556e128730cc <unknown>\n",
            "#23 0x7e11319b1ac3 <unknown>\n",
            "\n",
            "Data has been saved to 'scraped_profiles.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project: JobScrape360 - Python Job Scraper for Lahore**\n",
        "\n",
        "Description:\n",
        "This script automates the process of scraping Python job postings from Indeed Pakistan.\n",
        "It extracts information such as job titles, company names, locations, and job descriptions,\n",
        "and saves the data in both CSV and Excel formats for further analysis."
      ],
      "metadata": {
        "id": "Mq2-dRip_8q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach for printing on screen/console"
      ],
      "metadata": {
        "id": "KoMblPSTAYrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Project: JobScrape360 - Python Job Scraper for Lahore\n",
        "\n",
        "Description:\n",
        "This script automates the process of scraping Python job postings from Indeed Pakistan.\n",
        "It extracts information such as job titles, company names, locations, and job descriptions,\n",
        "and saves the data in both CSV and Excel formats for further analysis.\n",
        "\n",
        "Features:\n",
        "1. Automates job search for \"Python Developer\" in Lahore on Indeed.\n",
        "2. Extracts details such as job title, company name, location, and description.\n",
        "3. Saves the scraped data to a CSV file and an Excel workbook for convenience.\n",
        "4. Implements pagination to navigate through all job listings.\n",
        "5. Simulates human-like behavior with randomized delays to avoid bot detection.\n",
        "\n",
        "Modules Used:\n",
        "- Selenium: For browser automation and interaction with dynamic elements.\n",
        "- random: To add randomized delays for human-like interactions.\n",
        "- csv: To write scraped data to a structured CSV file.\n",
        "- openpyxl: To save data into an Excel workbook.\n",
        "- time: For managing delays during scraping.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from openpyxl import Workbook\n",
        "\n",
        "# Helper function to simulate human-like random delays\n",
        "def random_sleep(min_time=2, max_time=5):\n",
        "    \"\"\"\n",
        "    Introduces a randomized delay to mimic human interaction.\n",
        "\n",
        "    Args:\n",
        "        min_time (int): Minimum sleep time in seconds.\n",
        "        max_time (int): Maximum sleep time in seconds.\n",
        "    \"\"\"\n",
        "    time.sleep(random.uniform(min_time, max_time))\n",
        "\n",
        "# Step 1: Set up the WebDriver (Chrome in this case)\n",
        "# Using ChromeDriverManager to manage driver installation automatically\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "driver.implicitly_wait(10)  # Set an implicit wait for element loading\n",
        "\n",
        "# Step 2: Create a CSV file and write the headers\n",
        "csv_file = open('lahore_python_jobs.csv', mode='w', newline='', encoding='utf-8')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['Job Title', 'Company Name', 'Location', 'Job Description'])  # Add column headers\n",
        "\n",
        "# Step 3: Create an Excel workbook and add headers\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Python Jobs\"\n",
        "ws.append(['Job Title', 'Company Name', 'Location', 'Job Description'])  # Add column headers\n",
        "\n",
        "# Step 4: Navigate to Indeed Pakistan job search page\n",
        "driver.get(\"https://pk.indeed.com/\")\n",
        "random_sleep(3, 6)\n",
        "\n",
        "# Step 5: Enter the job title in the search box\n",
        "job_search_box = driver.find_element(By.ID, \"text-input-what\")\n",
        "for char in \"Python Developer\":  # Simulate typing for \"Python Developer\"\n",
        "    job_search_box.send_keys(char)\n",
        "    random_sleep(0.1, 0.3)\n",
        "\n",
        "# Step 6: Enter the location in the location search box\n",
        "location_search_box = driver.find_element(By.ID, \"text-input-where\")\n",
        "location_search_box.clear()  # Clear the default location\n",
        "random_sleep(1, 2)\n",
        "location_search_box.send_keys(\"Lahore\")  # Set the location to Lahore\n",
        "random_sleep(1, 2)\n",
        "\n",
        "# Submit the search by pressing ENTER\n",
        "location_search_box.send_keys(Keys.ENTER)\n",
        "random_sleep(5, 7)\n",
        "\n",
        "# Function to scrape jobs from the current page\n",
        "def scrape_jobs_from_page():\n",
        "    \"\"\"\n",
        "    Scrapes job details from the current page and writes them to CSV and Excel files.\n",
        "    \"\"\"\n",
        "    jobs = driver.find_elements(By.CLASS_NAME, 'job_seen_beacon')  # Locate job postings\n",
        "    for job in jobs:\n",
        "        try:\n",
        "            # Click the job title link to open the job description\n",
        "            job_title_link = job.find_element(By.CSS_SELECTOR, 'a.jcs-JobTitle')\n",
        "            job_title = job_title_link.text\n",
        "            job_title_link.click()\n",
        "            random_sleep(3, 5)\n",
        "\n",
        "            # Extract job details\n",
        "            job_title_on_page = driver.find_element(By.XPATH, \"//h2[contains(@class,'jobsearch-JobInfoHeader-title')]\").text\n",
        "            company_name = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='inlineHeader-companyName']\").text\n",
        "            job_location = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='inlineHeader-companyLocation']\").text\n",
        "            job_description = driver.find_element(By.ID, \"jobDescriptionText\").text\n",
        "\n",
        "            # Save details to the CSV file\n",
        "            csv_writer.writerow([job_title_on_page, company_name, job_location, job_description])\n",
        "\n",
        "            # Save details to the Excel sheet\n",
        "            ws.append([job_title_on_page, company_name, job_location, job_description])\n",
        "\n",
        "            # Navigate back to the main job list\n",
        "            driver.back()\n",
        "            random_sleep(5, 7)\n",
        "        except Exception as e:\n",
        "            # Log any errors encountered during scraping\n",
        "            print(f\"Failed to process job due to {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# Function to navigate to the next page\n",
        "def go_to_next_page():\n",
        "    \"\"\"\n",
        "    Navigates to the next page of job postings if available.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if next page is navigated, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Locate and click the \"Next Page\" button\n",
        "        next_button = driver.find_element(By.CSS_SELECTOR, \"a[data-testid='pagination-page-next']\")\n",
        "        next_button.click()\n",
        "        random_sleep(5, 7)\n",
        "        return True\n",
        "    except:\n",
        "        # If \"Next Page\" button is not found, log the end of pagination\n",
        "        print(\"No more pages to navigate.\")\n",
        "        return False\n",
        "\n",
        "# Step 7: Loop through all pages and scrape jobs\n",
        "while True:\n",
        "    scrape_jobs_from_page()  # Scrape jobs on the current page\n",
        "    if not go_to_next_page():  # Attempt to go to the next page\n",
        "        break\n",
        "\n",
        "# Step 8: Clean up and save files\n",
        "driver.quit()  # Close the browser\n",
        "csv_file.close()  # Close the CSV file\n",
        "\n",
        "# Save the Excel workbook\n",
        "wb.save(\"lahore_python_jobs.xlsx\")\n",
        "print(\"Job scraping completed. Data saved to 'lahore_python_jobs.csv' and 'lahore_python_jobs.xlsx'.\")\n"
      ],
      "metadata": {
        "id": "Crp__FQaAf1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Project: JobScrape360 - Save Job Listings to CSV and Excel\n",
        "\n",
        "Description:\n",
        "This script automates the process of scraping Python job listings from Indeed Pakistan for Lahore.\n",
        "It extracts details such as job titles, company names, locations, and job descriptions,\n",
        "and saves the data into both a CSV file and an Excel workbook for analysis.\n",
        "\n",
        "Features:\n",
        "1. Automates job search for \"Python Developer\" in Lahore on Indeed.\n",
        "2. Extracts comprehensive details for each job posting.\n",
        "3. Saves the scraped data to a structured CSV file and an Excel workbook.\n",
        "4. Implements pagination to scrape job listings across multiple pages.\n",
        "5. Simulates human-like interaction with random delays to reduce detection.\n",
        "\n",
        "Modules Used:\n",
        "- Selenium: For browser automation and interaction with dynamic elements.\n",
        "- random: To add randomized delays for human-like interactions.\n",
        "- csv: To save scraped data in CSV format.\n",
        "- openpyxl: To save data into an Excel workbook.\n",
        "- time: For managing delays during scraping.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from openpyxl import Workbook\n",
        "\n",
        "# Helper function to simulate human-like random delays\n",
        "def random_sleep(min_time=2, max_time=5):\n",
        "    \"\"\"\n",
        "    Introduces a randomized delay to mimic human interaction.\n",
        "\n",
        "    Args:\n",
        "        min_time (int): Minimum delay in seconds.\n",
        "        max_time (int): Maximum delay in seconds.\n",
        "    \"\"\"\n",
        "    time.sleep(random.uniform(min_time, max_time))\n",
        "\n",
        "# Step 1: Set up the WebDriver (Chrome in this case)\n",
        "# Using ChromeDriverManager to ensure the correct driver version is installed automatically.\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "driver.implicitly_wait(10)  # Set an implicit wait for locating elements\n",
        "\n",
        "# Step 2: Create a CSV file and write the headers\n",
        "csv_file = open('lahore_python_jobs.csv', mode='w', newline='', encoding='utf-8')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['Job Title', 'Company Name', 'Location', 'Job Description'])  # Add column headers\n",
        "\n",
        "# Step 3: Create an Excel workbook and write the headers\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Python Jobs\"\n",
        "ws.append(['Job Title', 'Company Name', 'Location', 'Job Description'])  # Add column headers\n",
        "\n",
        "# Step 4: Navigate to the Indeed Pakistan job search page\n",
        "driver.get(\"https://pk.indeed.com/\")\n",
        "random_sleep(3, 6)\n",
        "\n",
        "# Step 5: Enter the job title in the search box\n",
        "job_search_box = driver.find_element(By.ID, \"text-input-what\")\n",
        "for char in \"Python Developer\":  # Simulate typing character by character\n",
        "    job_search_box.send_keys(char)\n",
        "    random_sleep(0.1, 0.3)\n",
        "\n",
        "# Step 6: Enter the location in the search box\n",
        "location_search_box = driver.find_element(By.ID, \"text-input-where\")\n",
        "location_search_box.clear()  # Clear the default location\n",
        "random_sleep(1, 2)\n",
        "location_search_box.send_keys(\"Lahore\")  # Set the location to Lahore\n",
        "random_sleep(1, 2)\n",
        "\n",
        "# Submit the search by pressing ENTER\n",
        "location_search_box.send_keys(Keys.ENTER)\n",
        "random_sleep(5, 7)\n",
        "\n",
        "# Function to scrape job details from the current page\n",
        "def scrape_jobs_from_page():\n",
        "    \"\"\"\n",
        "    Scrapes job details from the current page and saves them to both CSV and Excel files.\n",
        "    \"\"\"\n",
        "    jobs = driver.find_elements(By.CLASS_NAME, 'job_seen_beacon')  # Locate job postings\n",
        "    for job in jobs:\n",
        "        try:\n",
        "            # Click the job title link to open the job description\n",
        "            job_title_link = job.find_element(By.CSS_SELECTOR, 'a.jcs-JobTitle')\n",
        "            job_title_link.click()\n",
        "            random_sleep(3, 5)\n",
        "\n",
        "            # Extract job details from the job description page\n",
        "            job_title = driver.find_element(By.XPATH, \"//h2[contains(@class,'jobsearch-JobInfoHeader-title')]\").text\n",
        "            company_name = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='inlineHeader-companyName']\").text\n",
        "            job_location = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='inlineHeader-companyLocation']\").text\n",
        "            job_description = driver.find_element(By.ID, \"jobDescriptionText\").text\n",
        "\n",
        "            # Write the extracted details to the CSV file\n",
        "            csv_writer.writerow([job_title, company_name, job_location, job_description])\n",
        "\n",
        "            # Write the extracted details to the Excel sheet\n",
        "            ws.append([job_title, company_name, job_location, job_description])\n",
        "\n",
        "            # Navigate back to the job listings page\n",
        "            driver.back()\n",
        "            random_sleep(5, 7)\n",
        "        except Exception as e:\n",
        "            # Log any errors encountered during scraping\n",
        "            print(f\"Failed to process job due to: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# Function to navigate to the next page of job listings\n",
        "def go_to_next_page():\n",
        "    \"\"\"\n",
        "    Navigates to the next page of job postings if available.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successfully navigated to the next page, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        next_button = driver.find_element(By.CSS_SELECTOR, \"a[data-testid='pagination-page-next']\")\n",
        "        next_button.click()  # Click the \"Next Page\" button\n",
        "        random_sleep(5, 7)\n",
        "        return True\n",
        "    except:\n",
        "        # If the \"Next Page\" button is not found, assume the end of pagination\n",
        "        print(\"No more pages to navigate.\")\n",
        "        return False\n",
        "\n",
        "# Step 7: Loop through all pages and scrape job listings\n",
        "while True:\n",
        "    scrape_jobs_from_page()  # Scrape jobs on the current page\n",
        "    if not go_to_next_page():  # Navigate to the next page, if available\n",
        "        break\n",
        "\n",
        "# Step 8: Clean up and save the data\n",
        "driver.quit()  # Close the browser\n",
        "csv_file.close()  # Close the CSV file\n",
        "wb.save(\"lahore_python_jobs.xlsx\")  # Save the Excel workbook\n",
        "\n",
        "print(\"Job scraping completed. Data saved to 'lahore_python_jobs.csv' and 'lahore_python_jobs.xlsx'.\")\n"
      ],
      "metadata": {
        "id": "WfZyOM6nAne3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}